# -*- coding: utf-8 -*-
"""Code_Eye.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RBFZ4AMnuYWwkRJ7k_hUaZvhpJKi_FG5
"""



# check Pillow version number
import PIL
print('Pillow Version:', PIL.__version__)



# load and display an image with Matplotlib
from matplotlib import image
from matplotlib import pyplot
# load image as pixel array
data = image.imread('/content/drive/My Drive/Colab Notebooks/project prog/REFUGE-Validation400/REFUGE-Validation400/V0002.jpg')
# summarize shape of the pixel array
print(data.dtype)
print(data.shape)
# display the array of pixels as an image
pyplot.imshow(data)
pyplot.show()

import pandas as pd
data=pd.read_excel('/content/drive/My Drive/Colab Notebooks/project prog/REFUGE-Validation400/Fovea_locations.xlsx')

data.head()

X_test_coord=data['Fovea_X']
Y_test_coord=data['Fovea_Y']

import matplotlib.pyplot as plt
plt.scatter(X_test_coord[0],Y_test_coord[0])
plt.xlim(0,1500)
plt.ylim(0,1600)





# load image and convert to and from NumPy array
import numpy as np
from PIL import Image
from numpy import asarray
# load the image
data=np.zeros((400,100,100,3))
for i in range(1,201):
  path= "/content/drive/My Drive/Colab Notebooks/project prog/REFUGE-Validation400/REFUGE-Validation400/V" +str(i)+".jpg"

  image = Image.open(path)

# convert image to numpy array
# resize image and ignore original aspect ratio
  img_resized = image.resize((100,100))
# report the size of the thumbnail
  #print(img_resized.size)

  data[i] = asarray(img_resized)

data1=data

#RGB Conversion to black and white
X=[0.3,0.59,0.11]
data_temp=np.zeros((400,100,100))
for i in range(400):
  data_temp[i]=np.dot(data1[i],X)



#min(X_test_coord)
#max(Y_test_coord)
X_test_coord=(X_test_coord).values
Y_test_coord=(Y_test_coord).values
'''
X_test_coord=np.around(X_test_coord)
Y_test_coord=np.around(Y_test_coord)
'''

#preprocessing
data_temp=data_temp/255.0

from sklearn.model_selection  import train_test_split
X_train,X_test,x_train_coord,x_test_coord,y_train_coord,y_test_coord=train_test_split(data_temp,X_test_coord,Y_test_coord,test_size=0.2)

#Using channels last
X_train=X_train.reshape(X_train.shape[0],100,100,1)
X_test=X_test.reshape(X_test.shape[0],100,100,1)

X_train.shape[0]



! pip install keras-tuner

import tensorflow as tf
from tensorflow import keras

#Building model
from keras.layers import Dense,LeakyReLU,ELU,PReLU,Dropout,Conv2D
from keras.models import Sequential
def  build_model(hp):
  model=keras.Sequential([
                          keras.layers.Conv2D(filters=hp.Int('Conv_1_filter',min_value=32,max_value=64,step=16),
                                              kernel_size=hp.Choice('Convo_1_kernels',values=[3,5]),
                                              activation='relu',
                                              input_shape=(X_train.shape[1],X_train.shape[2],1)),
                           keras.layers.Conv2D(filters=hp.Int('Conv_1_filter',min_value=64,max_value=128,step=16),
                                              kernel_size=hp.Choice('Convo_1_kernels',values=[3,5]),
                                              activation='relu'),
                                              
                           keras.layers.Conv2D(filters=hp.Int('Conv_1_filter',min_value=128,max_value=256,step=16),
                                              kernel_size=hp.Choice('Convo_1_kernels',values=[3,5]),
                                              activation='relu'),
                                              
                           keras.layers.Conv2D(filters=hp.Int('Conv_1_filter',min_value=256,max_value=512,step=16),
                                              kernel_size=hp.Choice('Convo_1_kernels',values=[3,5]),
                                              activation='relu'),
                          
                          keras.layers.Flatten(),
                          keras.layers.Dense(units=hp.Int('Dense_1_units',max_value=128,min_value=64,step=16),
                                             activation='relu'
                                             ),
                          
                          keras.layers.Dense(units=1,
                                             activation='linear'
                                             )
                          
                                             ])
  model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])
  model.summary()
  return(model)

from kerastuner import RandomSearch
import kerastuner.engine.hyperparameters as Hyperparameters

tuner_search=RandomSearch(build_model,
                          objective='val_mean_absolute_error',
                          max_trials=5
                          )
tuner_search.search(X_train,y_train_coord,epochs=3,validation_split=0.1)
model=tuner_search.get_best_models(num_models=1)[0]
model.fit(X_train,y_train_coord,epochs=500,validation_split=0.2,initial_epoch=3)

preds_y=model.predict(X_test)
#We train one after the another for both x_coords and y_coords







'''
#Regression problem
NN_model = Sequential()

# The Input Layer :
NN_model.add(Dense(128, kernel_initializer='normal',input_dim = train.shape[1], activation='relu'))

# The Hidden Layers :
NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))
NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))
NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))

# The Output Layer :
NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))

# Compile the network :
NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])
NN_model.summary()

'''







arr_x=np.zeros(len(preds_x))
arr_y=np.zeros(len(preds_x))
for i in range(len(preds_x)):
  arr_x[i]=preds_x[i][0]
  arr_y[i]=preds_y[i][0]

(pred_dict1)=pd.DataFrame(arr_y,columns=['y'])

arr_x=arr_x.reshape(80,1)

preds=pd.concat([pred_dict,pred_dict1],axis=1)

preds

